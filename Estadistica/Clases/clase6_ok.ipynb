{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ed3c6e-2942-4c8c-9b13-d6026bfe56ad",
   "metadata": {},
   "source": [
    "# Estadística para Data Science: Cuaderno clase 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024cfe2-e20b-439e-9b46-031ccd96a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando librerías\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a114d5-db35-40f4-bdff-d43895b81b07",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# recordando: Distribución Binomial y probabilidades:\n",
    "\n",
    "Un experimento aleatorio donde solo se pueden obtener dos resultados, usualmente etiquetados como \"éxito\" o \"fracaso\", se puede llamar \"ensayo de Bernoulli\". \n",
    "Como un ensayo de Bernoulli tiene solo dos posibles resultados, se puede enmarcar como una pregunta de sí o no. Por ejemplo:\n",
    "\n",
    "¿Es la primera carta de un mazo barajado un as?\n",
    "¿Ganó Colo Colo su último partido?\n",
    "\n",
    "La **distribución Binomial** con parámetros $n$ y $p$ es una **distribución de probabilidad discreta** del número de \"eventos exitosos\" en una secuencia de $n$ ensayos de Bernoulli, independientes entre sí, con una probabilidad fija $p$ de éxito (y $1-p$ de fracaso) en cada ensayo.\n",
    "\n",
    "\n",
    "Si $X$ es una variable aleatoria discreta tal que $X\\sim \\operatorname {Binomial} (n,p)$ entonces\n",
    "\n",
    "$$\\operatorname {E} [X]=np$$\n",
    "$$\\operatorname {Var} [X]=np(1-p)$$\n",
    "\n",
    "\n",
    "La función de probabilidad (o función de masa de probabilidad) \n",
    "de una Distribución Binomial es:\n",
    "\n",
    "$$\n",
    "P(k | p, n) = \\frac{n!}{k! (n-k)!}  p^k (1-p)^{n-k}\n",
    "$$ \n",
    "Y lo que hace esta función de masa de probabilidad es devolver la probabilidad de obtener exactamente $k$ eventos exitosos al hacer $n$ ensayos de un experimento donde la probabilidad de éxito está dada por $p$\n",
    "\n",
    "La función de distribución acumulada de una variable aleatoria $X\\sim \\operatorname {Binomial} (n,p)$ está dada por\n",
    "$$\n",
    "F(k;n,p) = P(X \\leq k) =  \\sum_{i=0}^{k} \\binom{n}{i} p^i (1-p)^{n-i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc5660-e99b-4c43-b616-7ea6ced41911",
   "metadata": {},
   "source": [
    "Volviendo a los ejemplos que hemos visto, si consideramos el lanzamiento de una moneda como nuestro experimento aleatorio, y definimos como evento exitoso obtener cara, la probabilidad de obtener exactamente $k=2$ caras al lanzar $n=4$ monedas, asumiendo una moneda justa ($p=0.5$) está dada por:\n",
    "\n",
    "$$\n",
    "P(k=2 | p=0.5, n=4) = \\frac{4!}{2! (4-2)!}  {\\frac{1}{2}}^2 (1-\\frac{1}{2})^{4-2} = \\frac{4 \\cdot 3 \\cdot 2 \\cdot 1}{\\cdot 2 \\cdot 1 \\cdot 2 \\cdot 1} \\frac{1}{4} \\frac{1}{4} = \\frac{3}{8} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cd7350-58a0-4429-9cc8-5f421a8812f6",
   "metadata": {},
   "source": [
    "Por supuesto que esto podríamos haberlo calculado de muchas otras formas. Por ejemplo:\n",
    "\n",
    "Al lanzar 4 monedas hay 16 posibles secuencias equiprobables:  \n",
    "\n",
    "CCCC  \n",
    "CCCS  \n",
    "CCSC  \n",
    "**CCSS**  \n",
    "CSCC  \n",
    "**CSCS**  \n",
    "**CSSC**  \n",
    "CSSS  \n",
    "SCCC  \n",
    "**SCCS**  \n",
    "**SCSC**  \n",
    "SCSS  \n",
    "**SSCC**  \n",
    "SSCS  \n",
    "SSSC  \n",
    "SSSS  \n",
    "  \n",
    "  \n",
    "Luego 6 de 16 tienen dos caras, por tanto, la probabilidad es:\n",
    "p = 6/16 = 3/8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43d0e5-6ad4-4de2-be68-b02a1a8c0dc6",
   "metadata": {},
   "source": [
    "Si quisiéramos graficar la distribución de probabilidad de la cantidad de caras al lanzar $n=4$ monedas justas ($p(cara)=0.5$, podríamos hacerlo usando la función de masa de probabilidad para calcular las probabilidades de obtener $k=\\{0,1,2,3,4\\}$ caras $n=4$. Luego usando un poco de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a682e-707d-40da-9c6f-b3e7376f5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos hacer un factorial con math.factorial()\n",
    "import math\n",
    "\n",
    "n=4\n",
    "p=0.5\n",
    "k=range(n+1)\n",
    "distribucion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb5e49d-f3c4-4c26-8cc2-23456ffa4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2160e-ca72-4c8a-8f02-810092ff666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in k:\n",
    "    distribucion.append(\n",
    "        math.factorial(n)/(math.factorial(i)*math.factorial(n-i))* \n",
    "    (p**i)*(1-p)**(n-i)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086cb977-6dd6-49db-aa4a-fb1402f3ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribucion = pd.Series(distribucion)\n",
    "print(distribucion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0431ca7d-0033-4532-a8fb-fff373bca430",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plot = distribucion.plot.bar( ylabel=\"Probabilidad\" ,rot=0,xlabel=\"Numero de caras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe154de6-8771-4763-ae8d-64e9b28fe553",
   "metadata": {},
   "source": [
    "Esta distribución de probabilidad que acabamos de graficar no se está basando en datos observados, sino ocupando razonamiento matemático basado en que conocemos/asumimos el modelo probabilístico. Se pueden estudiar y comprender sin tirar ninguna moneda.\n",
    "\n",
    "Las **distribuciones empíricas**, por otro lado, son las distribuciones de datos observados. Es decir, en este caso particular, lo que nos aparece al efectivamente tirar las 4 monedas y contar la cantidad de éxitos (caras). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24a1d2-76a4-449e-b3f2-249a1003a9c4",
   "metadata": {},
   "source": [
    "Ocupemos la funcion `muestreo_aleatorio` usada en las clases anteriores, para construir distribuciones empíricas del numero de caras que se obtienen al lanzar 4 monedas e ir acumulando datos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af356ec-90ba-403a-a8c3-393cd04a3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos la librería random\n",
    "import random\n",
    "\n",
    "def muestreo_aleatorio(n, em):\n",
    "    n=n\n",
    "    em=em\n",
    "    muestreo = [random.choice(em) for i in range(n)]\n",
    "    muestreo = pd.Series(muestreo)\n",
    "    return(muestreo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6140820b-045a-4fb4-a41e-b939a300ca5e",
   "metadata": {},
   "source": [
    "Lancemos las 4 monedas una vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b9603-a584-40ea-9748-787fd665a594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos el espacio muestral y el n\n",
    "em_moneda = ['C','S']\n",
    "n=4\n",
    "muestreo_aleatorio(n,em_moneda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ddb46-94a2-4e44-99e1-a20ae844b990",
   "metadata": {},
   "source": [
    "Ahora repitamos nuestro muestreo lanzando las 4 monedas unas 10 veces, contemos el número de caras cada vez y veamos como es la distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f88021-e63d-4385-bef8-ce695b021513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaramos una lista vacía para almacenar los datos\n",
    "lista_cantidad_caras =[]\n",
    "\n",
    "for i in range(10):\n",
    "    y = muestreo_aleatorio(n,em_moneda)  \n",
    "    lista_cantidad_caras.append(sum(y == \"C\")) # sumamos la cantidad de caras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e6976-3a5b-46d5-bbcd-8d13c705af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.Series(lista_cantidad_caras)\n",
    "print(x) # esta es la cantidad de caras que salieron en cada ensayo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25dfbf-b12c-4a19-8328-abdf7135c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_freq = x.value_counts().sort_index()\n",
    "print(x_freq)\n",
    "# esta es la cantidad de veces que salieron 0,1,2,3 y 4 caras en los 10 lanzamientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1c758-bd2d-405f-8dd8-b746fb890d91",
   "metadata": {},
   "source": [
    "Hagamos un gráfico de barras donde comparemos la distribución teórica con la empírica que acabamos de obtener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e9946-0392-4556-83dc-46796eeb1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prob = x_freq/len(x)\n",
    "df = pd.DataFrame({'empirica_10': x_prob,\n",
    "                   'teorica': distribucion})\n",
    "ax = df.plot.bar( ylabel=\"Probabilidad\" ,rot=0,xlabel=\"Numero de caras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d72a25-c347-4d2a-9355-10c7ad8ba323",
   "metadata": {},
   "source": [
    "Ahora veamos otra distribución empírica repitiendo el lanzamiento de las 4 monedas no 10 veces sino 30 veces, y luego 1000 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab13b9d-faec-4688-9890-a0b9a980cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaramos una lista vacía para almacenar los datos\n",
    "lista_cantidad_caras =[]\n",
    "\n",
    "for i in range(1000):\n",
    "    y = muestreo_aleatorio(n,em_moneda)  \n",
    "    lista_cantidad_caras.append(sum(y == \"C\")) # sumamos la cantidad de caras\n",
    "    \n",
    "x_prob_30 = pd.Series(lista_cantidad_caras[0:30]).value_counts(normalize = True).sort_index()\n",
    "x_prob_1000 = pd.Series(lista_cantidad_caras).value_counts(normalize = True).sort_index()\n",
    "\n",
    "df['empirica_30'] = x_prob_30\n",
    "df['empirica_1000'] = x_prob_1000\n",
    "df = df[['empirica_10', 'empirica_30', 'empirica_1000','teorica']]\n",
    "ax = df.plot.bar( ylabel=\"Probabilidad\" ,rot=0,xlabel=\"Numero de caras\",figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e12933-1fdb-4957-9fb2-50cc92d077c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# La Distribución Normal\n",
    "\n",
    "También llamada distribución Gaussiana o Campana de Gauss, una distribución normal es una distribución de probabilidad continua que aparece con mucha frecuencia en estadística y teoría de probabilidades. Es una distribución unimodal y simétrica, y se describe usando dos parámetros: El promedio de la distribución $\\mu$ y la desviación estándar $\\sigma$. La notación habitual es\n",
    "\n",
    "$$\n",
    "X \\sim \\mbox{N}(\\mu,\\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb675a7-f84f-4319-9dfc-76298d232f2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "La función de densidad de probabilidad de una Distribución Normal es:\n",
    "$$\n",
    "p(X | \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma}  \\exp \\left( -\\frac{(X - \\mu)^2}{2\\sigma^2} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2fbd4-8067-47ac-83cc-ea16699f1340",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Distribución Normal estándar y estandarización de una variable\n",
    "\n",
    "La distribución normal estándar es un caso especial de la función donde $\\mu =0$ y $\\sigma =1$. \n",
    "Es posible relacionar todas las variables aleatorias normales con la distribución normal estándar, ya que   \n",
    "si $X\\,\\sim N(\\mu ,\\sigma)\\,$ entonces  \n",
    "$$Z = \\frac{X - \\mu}{\\sigma} \\!$$\n",
    "es una variable aleatoria normal estándar: $Z\\,\\sim  N(0,1)\\,$.\n",
    "La transformación de una distribución $X\\,\\sim N(\\mu ,\\sigma)\\,$  en una $N(0, 1)$ se llama normalización, estandarización o tipificación de la variable $X$.\n",
    "\n",
    "Esta transformación es bien famosa y útil en muchas situaciones y no solo para una variable con distribución normal, ya que en términos generales, cualquier variable a la que se le aplique esta transformación queda medida en unidades estándar, es decir, en el número de desviaciones estándar sobre (o bajo) el promedio.\n",
    "\n",
    "Ahora vamos a graficar una distribución normal con media $\\mu = 0$ y desviación estándar $\\sigma = 1$. A diferencia de la distribución binomial, la imagen de la distribución normal muestra una curva suave en lugar de barras \"similares a histogramas\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7c865-164c-4c4b-9519-b8a01db82cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mu = 0\n",
    "variance = 1\n",
    "sigma = np.sqrt(variance)\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 100)\n",
    "\n",
    "fig = sns.lineplot(x = x, y = stats.norm.pdf(x, mu, sigma))\n",
    "# scipy.stats.norm.pdf(x,mu,sigma) es un método de scipy \n",
    "# que evalua la función de densidad de probabilidad de una normal\n",
    "# de media mu, desviacion estándar sigma en los valores x.\n",
    "\n",
    "plt.xlabel('Valores observados')\n",
    "plt.ylabel('Densidad de probabilidad')\n",
    "\n",
    "sns.despine() # para remover las líneas de arriba y la derecha.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13348f31-8110-4744-9c15-4fbf757b6080",
   "metadata": {},
   "source": [
    "### Algunas propiedades de la distribución normal\n",
    "\n",
    "1. Es simétrica respecto de su media $\\mu$.\n",
    "2. La moda y la mediana son ambas iguales a la media $\\mu$\n",
    "3. Los puntos de inflexión de la curva se dan para $\\mu -\\sigma$ y $x=\\mu +\\sigma$.\n",
    "4. Distribución de probabilidad en un entorno de la media:\n",
    "en el intervalo $\\mu -\\sigma ,\\mu +\\sigma$ se encuentra comprendida, aproximadamente, el 68,26 % de la distribución;\n",
    "en el intervalo $\\mu -2\\sigma ,\\mu +2\\sigma$ se encuentra, aproximadamente, el 95,44 % de la distribución;\n",
    "en el intervalo $\\mu -3\\sigma ,\\mu +3\\sigma$ se encuentra comprendida, aproximadamente, el 99,74 % de la distribución.  \n",
    "Estas propiedades son muy útiles para el establecimiento de intervalos de confianza. Veámoslo en un gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77219811-0aaf-42ab-b990-bdc6ad815c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=False)\n",
    "\n",
    "mu = 0\n",
    "variance = 1\n",
    "sigma = np.sqrt(variance)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "sns.lineplot(x = x, y = stats.norm.pdf(x, mu, sigma), ax=axes[0])\n",
    "\n",
    "\n",
    "sns.lineplot(x = x, y = stats.norm.pdf(x, mu, sigma), ax=axes[1])\n",
    "\n",
    "\n",
    "x_fill1 = np.arange(-1, 1, 0.001)\n",
    "x_fill2 = np.arange(-2, 2, 0.001)\n",
    "\n",
    "y_fill1 = stats.norm.pdf(x_fill1,0,1)\n",
    "y_fill2 = stats.norm.pdf(x_fill2,0,1)\n",
    "\n",
    "axes[0].fill_between(x_fill1,y_fill1,0, alpha=0.2, color='blue')\n",
    "axes[1].fill_between(x_fill2,y_fill2,0, alpha=0.2, color='blue')\n",
    "\n",
    "axes[0].set_title(\"Shaded Area = 68.3%\")\n",
    "axes[1].set_title(\"Shaded Area = 95.4%\")\n",
    "\n",
    "axes[0].set(xlabel='Observed value', ylabel='Probability density')\n",
    "axes[1].set(xlabel='Observed value', ylabel='Probability density')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75c8d4-fc81-4d19-83a3-218c5f1f5436",
   "metadata": {},
   "source": [
    "¿Qué pasa si movemos los parámetros $\\mu$ y $\\sigma$. Veámoslo gráficamente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff2cdb-6e18-4426-9825-2b23db539f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, variemos mu\n",
    "mu_1 = 4\n",
    "mu_2 = 7\n",
    "variance = 1\n",
    "sigma = np.sqrt(variance)\n",
    "x = np.linspace(1, 10, 100)\n",
    "y1 = stats.norm.pdf(x, mu_1, sigma)\n",
    "y2 = stats.norm.pdf(x, mu_2, sigma)\n",
    "\n",
    "\n",
    "fig = sns.lineplot(x = x, y = y1)\n",
    "# estas dos líneas son para que compartan el mismo eje x y los ticks no se plotteen dos veces\n",
    "ax2=fig.twinx()\n",
    "ax2.tick_params(left=False, labelleft=False, top=False, labeltop=False,\n",
    "                   right=False, labelright=False, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(x = x, y = y2, ax=ax2, linestyle='--')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3715ce-2402-44ab-ad44-8096b1cb005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora con sigma\n",
    "mu = 5\n",
    "variance = 1\n",
    "sigma = np.sqrt(variance)\n",
    "x = np.linspace(1, 10, 100)\n",
    "y1 = stats.norm.pdf(x, mu, 1)\n",
    "\n",
    "variance = 2\n",
    "sigma = np.sqrt(variance)\n",
    "y2 = stats.norm.pdf(x, mu, 2)\n",
    "\n",
    "\n",
    "fig = sns.lineplot(x = x, y = y1)\n",
    "\n",
    "ax2=fig.twiny()\n",
    "ax2.tick_params(left=False, labelleft=False, top=False, labeltop=False,\n",
    "                   right=False, labelright=False, bottom=False, labelbottom=False)\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(x = x, y = y2, ax=ax2, linestyle='--')\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15fa5b-cb31-4924-9da0-99a18063d119",
   "metadata": {},
   "source": [
    "Al variar $\\mu$ con $\\sigma$ constante, la distribución se mueve en el eje X, estando siempre centrada en el nuevo $\\mu$ pero manteniendo la misma forma.\n",
    "Al variar $\\sigma$ con $\\mu$ constante, la distribución sigue centrada en el mismo punto, pero al aumentar $\\sigma$ la distribución se va \"ensanchando\" o ampliando. Es importante notar que cuando ampliamos la distribución, la altura del peak se reduce. Esto tiene que suceder: de la misma manera que las alturas de las barras que usamos para graficar una distribución binomial discreta deben sumar 1, el área total bajo la curva para la distribución normal debe ser igual a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ccdf7-61ac-407c-bf35-4102dd9a4667",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recordemos: \n",
    "\n",
    "* Inferencia: Usar datos y razonamiento sobre la muestra para decir cosas sobre la población.\n",
    "* Población: El conjunto completo de sujetos de interés\n",
    "* Parámetro: una métrica de la población.\n",
    "* Muestra: Un subconjunto de la población.\n",
    "* Estadístico: una métrica de la muestra\n",
    "* Estimador:  Un estadístico usado para estimar un parámetro desconocido de la población"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fecd61",
   "metadata": {},
   "source": [
    "## Muestreo Aleatorio Simple\n",
    "\n",
    "\n",
    "\n",
    "Independientemente de cómo defina la población, el punto crítico es que la muestra es un subconjunto de la población, y nuestro objetivo es utilizar nuestro conocimiento de la muestra para sacar inferencias sobre las propiedades de la población. La relación entre los dos depende del procedimiento por el cual se seleccionó la muestra. Este procedimiento se denomina método de muestreo y es crucial entender por qué es importante.\n",
    "\n",
    "\n",
    "\n",
    "![srs1](https://github.com/vmlandae/datasets_eds/blob/main/clase6/srs1.png?raw=true)\n",
    "Imaginemos que tenemos una bolsa que contiene 10 fichas. Cada ficha tiene impresa una letra única, por lo que podemos distinguir entre las 10 fichas. Las fichas vienen en dos colores, blanco y negro. Este conjunto de fichas es la población de interés y se representa gráficamente a la izquierda de la figura.  Como vemos, hay 4 fichas negras y 6 blancas, pero siguiendo con la abstracción, no lo sabríamos a menos que miráramos dentro de la bolsa.\n",
    "Imaginemos que sacamos 4 fichas, sin reposición, de la bolsa. Si quisiera, podría volver a colocar todas las fichas en la bolsa y repetir el experimento, como se muestra en el lado derecho de la figura. Cada vez se obtienen resultados diferentes, pero el procedimiento es idéntico en cada caso. Debido a que agitamos la bolsa antes de sacar las fichas, parece razonable pensar que todas las fichas tienen la misma probabilidad de ser seleccionadas. Un procedimiento en el que cada miembro de la población tiene la misma probabilidad de ser seleccionado se denomina muestra aleatoria simple. El hecho de que no hayamos vuelto a colocar las fichas en la bolsa después de sacarlas significa que no se puede observar lo mismo dos veces y, en tales casos, se dice que las observaciones se han muestreado sin reemplazo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049a9c5-cd38-49cf-ae07-ea06a2075eb1",
   "metadata": {},
   "source": [
    "Consideremos otra forma de muestrear: Supongamos que mi sobrino abrió la bolsa y decidió sacar cuatro fichas negras sin volver a poner ninguna en la bolsa. Este esquema de muestreo sesgado se representa en la siguiente imagen. Ahora considera el valor probatorio de ver 4 fichas negras y 0 fichas blancas. Claramente, depende del esquema de muestreo. Si sabemos que el esquema de muestreo está sesgado para seleccionar solo fichas negras, entonces una muestra que consta solo de fichas negras no nos dice mucho sobre la población. Y peor todavía, si no sabemos que el esquema de muestreo está sesgado, las inferencias que podamos hacer sobre la población van a tener sesgos.\n",
    "\n",
    "\n",
    "![brs](https://github.com/vmlandae/datasets_eds/blob/main/clase6/brs.png?raw=true)\n",
    "\n",
    "Un tercer procedimiento diferente sería cuando cerramos los ojos, sacudimos la bolsa y sacamos una ficha, pero ahora registramos la observación y volvemos a poner la ficha en la bolsa. Nuevamente cerramos los ojos, sacudimos la bolsa y sacamos una ficha, y repetimos el procedimiento hasta tener las 4. Los conjuntos de datos generados de esta manera siguen siendo muestras aleatorias simples, pero debido a que volvemos a colocar las fichas en la bolsa se denomina muestreo con reemplazo. La diferencia entre esta situación y la primera es que es posible observar el mismo miembro de la población varias veces.\n",
    "\n",
    "![srs2](https://github.com/vmlandae/datasets_eds/blob/main/clase6/srs2.png?raw=true)\n",
    "\n",
    "\n",
    "Esto por supuesto es muy posible de hacer con fichas o dados pero no tanto con experimentos que involucran seres humanos, donde en general los muestreos tienden a ser sin reemplazo. Sin embargo, la mayor parte de la teoría estadística se basa en la suposición de que los datos surgen de una muestra aleatoria simple con reemplazo. En la vida real, esto usualmente no es muy importante, ya que si la población de interés es grande (de seguro más que 10 fichas), la diferencia entre el muestreo con y sin reemplazo es muy pequeña para preocuparse. La diferencia entre muestras aleatorias simples y muestras sesgadas, por otro lado, no es algo tan fácil de descartar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f4180f-47d6-49df-a5e8-037618d4551b",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "## ¿Por qué la distribución normal es tan importante?\n",
    "\n",
    "### Ley de los grandes números:\n",
    "Esta ley aplica a muchos estadísticos, quizá el ejemplo más claro es cuando se aplica a la media de la muestra. Lo que establece la ley de los grandes números es que a medida que la muestra se hace más grande, la media de la muestra tiende a acercarse a la verdadera media de la población $\\mu$. O, para decirlo con un poco más de precisión, a medida que el tamaño de la muestra \"se acerca\" al infinito ($N \\to \\infty$), la media de la muestra se acerca a la media de la población ($\\bar{X} \\to \\mu $). Técnicamente, la ley de los grandes números pertenece a cualquier estadístico que pueda describirse como un promedio de cantidades independientes, como una proporción de una muestra, o como la varianza de una muestra, que se puede reescribir como una especie de promedio y, por lo tanto, está sujeta a la ley de los grandes números. Sin embargo, el valor mínimo de una muestra, por ejemplo, no puede escribirse como un promedio de nada y, por lo tanto, no se rige por la ley de los grandes números. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f326f4-e125-41f5-ab5f-cdec6cdc3e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Teorema Central del Límite:\n",
    "\n",
    "\n",
    "En condiciones muy generales, si $S_{n}$ es la suma de $n$ variables aleatorias independientes, con media conocida y varianza no nula pero finita, entonces la función de distribución de $S_{n}$ \"se aproxima bien\" a una distribución normal.   \n",
    "\n",
    "Planteado de otra manera, la distribución muestral de un estadístico se refiere a la distribución de algun estadístico muestral entre muchas muestras extraídas de la misma población. Bajo el supuesto de independencia de las observaciones (que se puede asumir al hacer un muestreo aleatorio simple), esta distribución teórica (pues requiere de infinitos muestreos) distribuye normal y tiene ciertas propiedades.  \n",
    "Gran parte de la estadística clásica se ocupa de hacer inferencias a partir de muestras (pequeñas) a poblaciones (muy grandes). Por lo general, una muestra se extrae con el objetivo de medir algo (con un estadístico de muestra) o modelar algo (con un modelo estadístico o de aprendizaje automático). Dado que nuestra estimación o modelo se basa en una muestra, podría haber un error; podría ser diferente si tomáramos una muestra diferente. Por lo tanto, estamos interesados en ver  cuán diferente podría ser; una preocupación clave es la variabilidad del muestreo. Si tuviéramos muchos datos, podríamos extraer muestras adicionales y observar la distribución de una muestra estadística directamente.\n",
    "\n",
    "\n",
    "Todo esto suena un poco vago y a la vez abstracto: veámoslo en la práctica, y para eso volvemos sobre el concepto de Distribución de muestreo de un estadístico.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e67f28-03b5-4096-888b-f680776bccde",
   "metadata": {
    "tags": []
   },
   "source": [
    "Veámoslo de manera más empírica: carguemos un set de datos nuevo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3005d-214a-49d4-b05a-4292df1dc72b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Datos Mineduc: rendimiento educacion básica y media 2021 en el Bío Bío.\n",
    "Leamos el siguiente dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b99025-5058-47df-bef0-dd94bb9664a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est = pd.read_csv(\"https://raw.githubusercontent.com/vmlandae/datasets_eds/main/clase5/rendimiento_2021_8va.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbee306-215d-4b11-89a4-1e8411aa1263",
   "metadata": {},
   "source": [
    "Este dataset es un subconjunto de datos a nivel nacional del año 2021 facilitados por el mineduc en su [página de datos abiertos](https://datosabiertos.mineduc.cl/rendimiento-por-estudiante-2/), donde reportan el rendimiento por alumno de enseñanza básica y media. Este dataset fue filtrado y limpiado, para solo contener los estudiantes que se encontraban matriculados en instituciones de la Región del Bío Bío. La [documentación](https://github.com/vmlandae/datasets_eds/blob/main/clase5/ER%20Rendimiento%20por%20alumno%2C%20bases%20Web.pdf) nos permite revisar que es cada variable, pues no todas son tan intuitivas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d17552-25bb-4641-8adc-6084d129bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_est.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710fe90-80b0-4a53-9a22-2d3e553f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIT_FIN_R es la situación a final de año de un estudiante,\n",
    "# donde P: promovido, R: reprobado, Y: Retirado, T: trasladado (se cambió de colegio) y \n",
    "# algunos datos en blanco sin información. Vamos a filtrar para dejar solo P,R,Y en el dataset\n",
    "# porque así estamos contando a cada alumno solo una vez (los que se cambian tienen más de un registro)\n",
    "\n",
    "df =  df_est.loc[df_est['SIT_FIN_R'].isin(['P','R','Y'])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd02c28-a55f-4933-bd5f-14a81ea02d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_est['MRUN'].nunique())\n",
    "print(df_est.shape)      \n",
    "print(df['MRUN'].nunique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a88e9c-cfa7-4bd2-b787-1ae27fa2cc4c",
   "metadata": {},
   "source": [
    "Estos datos son censales, por tanto si quisiéramos saber, por ejemplo, la proporción de alumnos de básica y media en la región del Bío Bío el año 2021 que asistieron a un establecimiento municipal, por ejemplo, me basta con calcularlo usando la variable `COD_DEPE2`, que cuando es 1, indica un colegio de dependencia municipal. Entonces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a8e438-c775-4764-9b4c-6491bad015f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_municipal = round( (df['COD_DEPE2']==1).mean(),4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873843f6-182f-4bae-b0bb-2c39ee1bc961",
   "metadata": {},
   "source": [
    "No vamos a ver cual es el valor real todavía, sino que construiremos distribuciones de muestreo de la proporción haciendo muchos muestreos aleatorios simples (sin reemplazo) para $n=30$, $n=100$, $n=1000$ y $n=5000$, calculando la proporción estimada para cada muestreo y construyendo las tres distribuciones de muestreo de la proporción estimada. Luego, de estas distribuciones, vamos a ver como son las proporciones que estoy estimando con distintas muestras, y como finalmente se comparan con la proporción real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e65257-48db-4897-ab91-01ef602e758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos variables para almacenar las proporciones estimadas de cada muestreo\n",
    "\n",
    "municipal30 = []\n",
    "municipal100 = []\n",
    "municipal1000 = []\n",
    "municipal5000 = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    municipal30.append((df['COD_DEPE2']==1).sample(30).mean())\n",
    "    municipal100.append((df['COD_DEPE2']==1).sample(100).mean())\n",
    "    municipal1000.append((df['COD_DEPE2']==1).sample(1000).mean())\n",
    "    municipal5000.append((df['COD_DEPE2']==1).sample(5000).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c4482-2e46-48d8-b10d-6996f6a00c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "municipal30 = pd.Series(municipal30)\n",
    "municipal100 = pd.Series(municipal100)\n",
    "municipal1000 = pd.Series(municipal1000)\n",
    "municipal5000 = pd.Series(municipal5000)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab09e8a-8b92-42f6-8832-cace333ee1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "plt.hist(municipal30, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'blue',alpha=0.4)\n",
    "plt.title(\"Distribución de muestreo con n=30\")\n",
    "plt.show()    \n",
    "plt.hist(municipal100, edgecolor = 'black', linewidth = 1.2, bins = 25,alpha=0.4)\n",
    "plt.title(\"Distribución de muestreo con n=100\")\n",
    "plt.show()    \n",
    "\n",
    "plt.hist(municipal1000, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'purple',alpha=0.4)\n",
    "plt.title(\"Distribución de muestreo con n=1000\")\n",
    "plt.show()    \n",
    "plt.hist(municipal5000, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'green',alpha=0.4)\n",
    "plt.title(\"Distribución de muestreo con n=5000\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fefa50-89e1-4d27-92f8-162fd87123a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "plt.hist(municipal30, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'blue',alpha=0.4)\n",
    "plt.hist(municipal100, edgecolor = 'black', linewidth = 1.2, bins = 25,alpha=0.4)\n",
    "plt.hist(municipal1000, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'purple',alpha=0.4)\n",
    "plt.hist(municipal5000, edgecolor = 'black', linewidth = 1.2, bins = 25, color = 'green',alpha=0.4)\n",
    "plt.title(\"Distribuciones de muestreo con distintos tamaños de muestra\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95cb100-bb83-452c-992c-666abaf55cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n para el muestreo con n=30, el promedio de la distribución muestral es:\",\n",
    "      round(municipal30.mean(),4), \"\\n y la desviación estándar de la distribución muestral es:\",\n",
    "      round(municipal30.std(),4),\n",
    "      \"\\n para el muestreo con n=100, el promedio de la distribución muestral es:\",\n",
    "      round(municipal100.mean(),4), \"\\n y la desviación estándar de la distribución muestral es:\",\n",
    "      round(municipal100.std(),4),\n",
    "      \n",
    "      \"\\n para el muestreo con n=1000, el promedio de la distribución muestral es:\",\n",
    "      round(municipal1000.mean(),4), \"\\n y la desviación estándar de la distribución muestral es:\",\n",
    "      round(municipal1000.std(),4),\n",
    "      \"\\n para el muestreo con n=5000, el promedio de la distribución muestral es:\",\n",
    "      round(municipal5000.mean(),4), \"\\n y la desviación estándar de la distribución muestral es:\",\n",
    "      round(municipal5000.std(),4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be083493-10af-47ab-b676-be017047fabc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para proporciones, el teorema del límite central dice que cuando las observaciones son independientes y el tamaño de la muestra es lo suficientemente grande, la proporción de la muestra $\\hat{p}$ tiende a seguir una distribución normal con la siguiente media y **error estándar** (que es la desviación estándar de esta distribución de muestreo):\n",
    "\n",
    "$$\\mu_{\\hat{p}} = p $$  \n",
    "  \n",
    "  \n",
    "$$SE_{\\hat{p}} = \\sqrt{\\frac{p(1 - p)}{n}  }$$\n",
    "\n",
    "El tamaño de la muestra se considera lo suficientemente grande para que el teorema del límite central aplique cuando $np \\geq 10$ and $n(1 - p)\\geq 10$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d56ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_municipal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19e3d6-8547-4ef6-8ed6-87b425750f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=30\n",
    "mu = prop_municipal \n",
    "sigma = np.sqrt(prop_municipal *(1-prop_municipal )/n)\n",
    "x = np.linspace(0, 1, 100)\n",
    "y1 = stats.norm.pdf(x, mu, sigma)\n",
    "\n",
    "fig = sns.lineplot(x = x, y = y1)\n",
    "\n",
    "ax2=fig.twinx()\n",
    "ax2.tick_params(left=False, labelleft=False, top=False, labeltop=False,\n",
    "                  right=False, labelright=False, bottom=False, labelbottom=False)\n",
    "\n",
    "sns.histplot(x = municipal30, ax=ax2,stat=\"proportion\")\n",
    "                \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ddcaa1-7e35-4cac-8591-e8dc642369cd",
   "metadata": {},
   "source": [
    "¡Fantástico!\n",
    "\n",
    "### Recordemos \n",
    "Se deben cumplir ciertas condiciones para que aplique el TLC:\n",
    "\n",
    "#### Independencia  \n",
    "Las observaciones muestreadas deben ser independientes. Esto es difícil de verificar, pero es más posible si: \n",
    "\n",
    "* Se utiliza un **muestreo/asignación aleatorios** y\n",
    "* En caso de muestreos sin remplazo, n < 10% de la población."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0186bc4",
   "metadata": {},
   "source": [
    "Ahora bien, en las aplicaciones en el mundo real, casi nunca observamos realmente la distribución de muestreo,y tampoco tengo el valor real de la proporción, y si podemos hacer el muestreo tantas veces como en este caso, podríamos haber calculado la proporción real directamente desde el dataset. Sin embargo, es bastante útil siempre pensar que un estimador puntual viene de esta distribución hipotética. Comprender la distribución de muestreo nos ayudará a caracterizar y dar sentido a los estimadores puntuales que sí podemos observar.\n",
    "\n",
    "### Aplicación del teorema del límite central a un escenario del mundo real\n",
    "Supongamos que no tuviéramos estos datos censales que estamos ocupando, y solo tuviésemos una muestra. No tendríamos como saber el parámetro de la proporción de la población, a menos que recolectáramos los datos ya fuera a través de una encuesta u otra forma, muy costoso y complicado de hacer por nosotros solos.  \n",
    "\n",
    "Para hacerlo más realista, vamos a tomar una muestra aleatoria simple de $n=100$ y trabajar con ella, y vamos a tratar de estimar la proporción de estudiantes en colegios municipales de la población del Bío Bío con ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf8d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra_100 = df.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce3444",
   "metadata": {},
   "source": [
    "En general, el promedio de una muestra (y la proporción de una muestra, que al final es un caso particular del promedio con unos y ceros) es un estimador puntual muy usado, ya que debido a sus propiedades se dice que es un buen estimador pues es *insesgado* (en promedio, el promedio de las medias muestrales es igual a la media poblacional) y *eficiente* (simplificando, que la varianza del estimador es más pequeña), propiedades matemáticas demostrables en las que no ahondaremos hoy. \n",
    "En fin, estimemos la proporción con nuestra muestra usando el promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_estimada_municipales = (muestra_100['COD_DEPE2']==1).mean()\n",
    "\n",
    "print(prop_estimada_municipales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7b1df-c808-4869-b1eb-bb7ed052534f",
   "metadata": {},
   "source": [
    "Suponiendo que solo tuviéramos esta información ¿la proporción de la muestra de la encuesta sería parte de una distribución de muestreo que distribuyera normal?   \n",
    "Podemos comprobar las condiciones del Teorema del Límite Central:   \n",
    "* Independencia. La encuesta es una muestra aleatoria simple de estudiantes de la región del Bío Bío, lo que significaría que las observaciones son independientes. \n",
    "* Condición de éxito-fracaso. Para verificar esta condición, necesitamos la proporción de la población, $p$, para verificar si tanto $np$ como $n(1-p)$ son mayores que 10. Sin embargo, en realidad no sabemos el valor del parámetro $p$!, ¡que es exactamente por lo que estamos tomado una muestra! En casos como estos, usamos $\\hat{p}$, o sea,`prop_estimada_municipales` como nuestra siguiente mejor manera de verificar la condición de éxito-fracaso:\n",
    "\n",
    "La proporción de la muestra, $\\hat{p}$ actúa como un sustituto razonable de $p$ en este chequeo, y cada valor en este caso está por sobre el mínimo de 10\n",
    "Esta aproximación también es útil cuando calculamos el error estándar de la proporción de la muestra:\n",
    "\n",
    "$$SE_{\\hat{p}} = \\sqrt{\\frac{p(1 - p)}{n}} \\approx \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_phat = math.sqrt(prop_estimada_municipales*(1-prop_estimada_municipales)/100)\n",
    "print(se_phat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85839028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparando con los valores reales que conocemos:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c425b8",
   "metadata": {},
   "source": [
    "### Intervalos de confianza para una proporción\n",
    "\n",
    "La proporción de la muestra $\\hat{p}$ provee un único valor posible para la proporción de la población $p$. \n",
    "Sin embargo, la proporción de la muestra no es perfecta y tendrá algún error estándar asociado a ella.\n",
    "Cuando se establece un estimado para la proporción de la población, es una mejor práctica proveer un *rango posible de valores* en vez de entregar solo el estimador puntual\n",
    "\n",
    "\n",
    "### Capturando el parámetro de la población\n",
    "\n",
    "Usar solo un estimador puntual es como ir a pescar en un lago turbio con un arpón. Podemos tirar un arpón cuando vemos un pez, pero probablemente fallemos. Por otro lado, si tiramos una red en esa área, tenemos una buena posibilidad de atrapar al pez. Un intervalo de confianza es como pescar con una red y representa un rango de valores posibles donde posiblemente encontremos el parámetro de la población.\n",
    "Si reportamos un estimador puntal $\\hat{p}$, muy probablemente no demos con la proporción de la población exacta.\n",
    "Por otra parte, si reportamos un rango de valores posibles, representando un intervalo de confianza tenemos una buena posibilidad de capturar el parámetro.\n",
    "\n",
    "\n",
    "\n",
    "### Construyendo un intervalo de confianza del 95%\n",
    "\n",
    "Nuestra proporción de la muestra $\\hat{p}$ es el valor más plausible de la proporción de la población, por lo que tiene sentido construir un intervalo de confianza en torno a este estimador puntual. El error estándar provee una guía para cuán grande debiésemos hacer el intervalo de confianza.\n",
    "El error estándar representa la desviación estándar del estimador puntual y cuando se satisfacen las condiciones del Teorema del Límite Central, el estimador puntual se aproxima a una distribución normal.\n",
    "En una distribución normal, 95% de los datos están dentro de 1.96 desviaciones estándar del promedio.\n",
    "Usando este principio, podemos construir un intervalo de confianza que se extienda en 1.96 veces el error estándar respecto de la proporción de la muestra para estar **95% seguros** de que el intervalo captura la proporción de la población:\n",
    "\n",
    "$$point estimate \\pm   1.96 \\times  SE $$\n",
    "\n",
    "$$\\hat{p} \\pm  1.96  \\sqrt{\\frac{p(1 -p)}{n}} $$\n",
    "\n",
    "Pero, ¿qué significa “95% seguros”? Supongamos que tomamos muchas muestras y construimos un intervalo de confianza de 95% en cada una. Entonces, alrededor del 95% de esos intervalos contendría el parámetro, $p$.\n",
    "\n",
    "\n",
    "\n",
    "### Cambiando el intervalo de confianza\n",
    "\n",
    "Supongamos que queremos considerar intervalos donde el intervalo de confianza sea mayor a 95%, como un intervalo de confianza de 99%. Recordemos la analogía de intentar atrapar un pez: si queremos estar más seguros de que lo atraparemos, debiésemos usar una red más ancha. Para crear un nivel de confianza de 99%, también debemos ampliar nuestro intervalo de 95%. Por otro lado, si queremos un intervalo con un menor nivel de confianza, como 90%, podemos usar un intervalo ligeramente más angosto que nuestro intervalo original de 95%.\n",
    "\n",
    "\n",
    "La estructura del intervalo de confianza de 95% provee una orientación sobre cómo hacer intervalos con diferentes niveles de confianza. El intervalo de confianza general de 95% para un estimador puntual que sigue una distribución normal es   \n",
    " $$point estimate \\pm   1.96 \\times  SE $$\n",
    "\n",
    "Hay tres componentes en este intervalo: el estimador puntual, “1.96” y el error estándar.\n",
    "La elección de 1.96 SE estaba basada en capturar 95% de los datos dado que el estimador está dentro de 1.96 veces el error estándar del parámetro alrededor del 95% de las veces. La elección de 1.96 corresponde a un intervalo de confianza de 95%.\n",
    "\n",
    "\n",
    "### Intervalo de confianza usando un nivel de confianza cualquiera\n",
    "\n",
    "Si un estimador puntual se aproxima bastante a un modelo normal con error estándar SE, entonces, un intervalo de confianza para el parámetro de la población es:  \n",
    "$$point estimate \\pm   z^{*} \\times  SE $$  \n",
    "\n",
    "donde $z^{*}$ corresponde al z-score que nos de el intervalo de confianza seleccionado.\n",
    "\n",
    "\n",
    "### Margen de Error\n",
    "En un intervalo de confianza, $z^{*}$ \\times SE es denominado el margen de error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde3673-92a2-4ccd-8de9-22e980f81dbb",
   "metadata": {},
   "source": [
    "## Teorema del límite central para el promedio:\n",
    "\n",
    "La distribución del promedio de la muestra se puede aproximar bien a partir de un modelo normal:\n",
    "\n",
    "$$ \\bar{X} \\sim \\mbox{N}(\\mu, SE ) $$\n",
    "\n",
    "\n",
    "donde $SE$ representa el error estándar, que es definido como la desviación estándar de la distribución de muestreo, con muestras de tamaño $n$. Si $\\sigma$ es desconocido, utilizamos $s$, que es la desviación estándar de la muestra (insesgada, o sea dividida por $n-1$). \n",
    "No profundizaremos en la prueba detallada de por qué $SE = \\frac{\\sigma}{\\sqrt{n}}$, pero notemos que en la medida de $n$ aumenta, $SE$ disminuye. En la medida en que el tamaño de la muestra aumenta, podemos esperar que las muestran arrojen promedios de muestra más consistentes, dado que la variabilidad entre los promedios de la muestra sería menor. \n",
    "\n",
    "\n",
    "Se deben cumplir ciertas condiciones para que aplique el TLC:\n",
    "\n",
    "Independiencia: Las observaciones muestreadas deben ser independientes. Esto es difícil de verificar, pero es más probable si:  \n",
    "* Se utiliza un muestreo/asignación aleatorios y\n",
    "* En caso de muestreos sin remplazo, n < 10% de la población.\n",
    "* Sample size / skew: Ya sea que la distribución de la población sea normal o que sea “skewed”, el tamaño de la muestra es grande. Mientras más “skewed” sea la distribución de la población, necesitamos una muestra más grande para que aplique el CLT. \n",
    "* Para distribuciones moderadamente “skewed” n > 30 es aceptable\n",
    "\n",
    "Esto también es difícil de verificar para la población,  pero podemos chequearlo utilizando los datos de la muestra y asumir que la muestra refleja lo que es la población.  \n",
    "\n",
    "\n",
    "**Importante:**\n",
    "\n",
    "El teorema del límite central dice que la distribución de probabilidad de la suma o el promedio de una gran muestra aleatoria extraída con reemplazo será aproximadamente normal, **independientemente de la distribución de la población de la que se extraiga la muestra.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b764e-9cf7-448c-8ae3-7b148bbafcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
